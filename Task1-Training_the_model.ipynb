{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "mid_term.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCAqHsLpolNK"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMYIcGvbHmfL",
        "outputId": "81d74988-504a-4cbd-83b5-6cfc1c5bb3aa"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.7.12\n",
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y36bdkOVWgL"
      },
      "source": [
        "#!pip install tensorflow\n",
        "#!pip install keras\n",
        "#!pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZLiNe-cV5FB",
        "outputId": "ef2c5a2e-1f05-40b5-dfa8-e8ae36d87961"
      },
      "source": [
        "!wget https://ember.elastic.co/ember_dataset_2017_2.tar.bz2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-12 16:14:59--  https://ember.elastic.co/ember_dataset_2017_2.tar.bz2\n",
            "Resolving ember.elastic.co (ember.elastic.co)... 34.107.161.234, 2600:1901:0:1f6d::\n",
            "Connecting to ember.elastic.co (ember.elastic.co)|34.107.161.234|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1751237573 (1.6G) [application/x-bzip2]\n",
            "Saving to: ‘ember_dataset_2017_2.tar.bz2’\n",
            "\n",
            "ember_dataset_2017_ 100%[===================>]   1.63G   109MB/s    in 17s     \n",
            "\n",
            "2021-10-12 16:15:16 (98.0 MB/s) - ‘ember_dataset_2017_2.tar.bz2’ saved [1751237573/1751237573]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzmCWYyzo0Q2"
      },
      "source": [
        "# Decompressing a .bz2 file\n",
        "!bzip2 -d ember_dataset_2017_2.tar.bz2"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO0rp_pdpRiU",
        "outputId": "55fc68eb-7f3c-4f4d-ec9e-c775165788a8"
      },
      "source": [
        "# Extracting from tar file\n",
        "!tar -xvf ember_dataset_2017_2.tar"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ember_2017_2/\n",
            "ember_2017_2/train_features_1.jsonl\n",
            "ember_2017_2/train_features_0.jsonl\n",
            "ember_2017_2/train_features_3.jsonl\n",
            "ember_2017_2/test_features.jsonl\n",
            "ember_2017_2/train_features_5.jsonl\n",
            "ember_2017_2/train_features_4.jsonl\n",
            "ember_2017_2/train_features_2.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V8z6_YOtEQD",
        "outputId": "5ba37e9d-b977-45d0-e0c3-b0e071a5a6d0"
      },
      "source": [
        "!git clone https://github.com/elastic/ember.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ember'...\n",
            "remote: Enumerating objects: 266, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 266 (delta 32), reused 45 (delta 14), pack-reused 192\u001b[K\n",
            "Receiving objects: 100% (266/266), 11.36 MiB | 26.99 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBQVa1A0ux2W"
      },
      "source": [
        "!cp -r ember/* ."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmxV2qw6uFMj",
        "outputId": "d2e9904c-e86e-4db4-a20b-991ba87c6008"
      },
      "source": [
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lief>=0.9.0\n",
            "  Downloading lief-0.11.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.31.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.1.5)\n",
            "Requirement already satisfied: lightgbm>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.2.3->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.3->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->-r requirements.txt (line 4)) (1.15.0)\n",
            "Installing collected packages: lief\n",
            "Successfully installed lief-0.11.5\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating ember.egg-info\n",
            "writing ember.egg-info/PKG-INFO\n",
            "writing dependency_links to ember.egg-info/dependency_links.txt\n",
            "writing requirements to ember.egg-info/requires.txt\n",
            "writing top-level names to ember.egg-info/top_level.txt\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "reading manifest file 'ember.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE.txt'\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/ember\n",
            "copying ember/__init__.py -> build/lib/ember\n",
            "copying ember/setup.py -> build/lib/ember\n",
            "copying ember/features.py -> build/lib/ember\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/__init__.py -> build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/setup.py -> build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/features.py -> build/bdist.linux-x86_64/egg/ember\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/setup.py to setup.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/features.py to features.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "ember.__pycache__.setup.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/ember-0.1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing ember-0.1.0-py3.7.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/ember-0.1.0-py3.7.egg\n",
            "Extracting ember-0.1.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding ember 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/ember-0.1.0-py3.7.egg\n",
            "Processing dependencies for ember==0.1.0\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for lightgbm==2.2.3\n",
            "Best match: lightgbm 2.2.3\n",
            "Adding lightgbm 2.2.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pandas==1.1.5\n",
            "Best match: pandas 1.1.5\n",
            "Adding pandas 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.62.3\n",
            "Best match: tqdm 4.62.3\n",
            "Adding tqdm 4.62.3 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for lief==0.11.5\n",
            "Best match: lief 0.11.5\n",
            "Adding lief 0.11.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for joblib==1.0.1\n",
            "Best match: joblib 1.0.1\n",
            "Adding joblib 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for ember==0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "2Dv8997WvWWU",
        "outputId": "de86f395-67db-499e-b584-48c9c9b833b7"
      },
      "source": [
        "import ember\n",
        "ember.create_vectorized_features(\"/content/ember_2017_2/\")\n",
        "ember.create_metadata(\"/content/ember_2017_2/\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.11.5-37bc2c9 found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n",
            "Vectorizing training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 900000/900000 [36:10<00:00, 414.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizing test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200000/200000 [08:08<00:00, 409.81it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha256</th>\n",
              "      <th>appeared</th>\n",
              "      <th>label</th>\n",
              "      <th>subset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d4206650743b3d519106dea10a38a55c30467c3d9f7875...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
              "      <td>2007-01</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099995</th>\n",
              "      <td>fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099996</th>\n",
              "      <td>fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099997</th>\n",
              "      <td>fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099998</th>\n",
              "      <td>fffe92f9593649c4a7050302368189de45e2c1c06b04ea...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099999</th>\n",
              "      <td>ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1100000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    sha256  ... subset\n",
              "0        0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  ...  train\n",
              "1        d4206650743b3d519106dea10a38a55c30467c3d9f7875...  ...  train\n",
              "2        c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  ...  train\n",
              "3        7f513818bcc276c531af2e641c597744da807e21cc1160...  ...  train\n",
              "4        ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  ...  train\n",
              "...                                                    ...  ...    ...\n",
              "1099995  fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...  ...   test\n",
              "1099996  fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...  ...   test\n",
              "1099997  fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...  ...   test\n",
              "1099998  fffe92f9593649c4a7050302368189de45e2c1c06b04ea...  ...   test\n",
              "1099999  ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...  ...   test\n",
              "\n",
              "[1100000 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "Z9G64-2537-G",
        "outputId": "a359cb87-e3a3-47ac-9911-e18420b11a78"
      },
      "source": [
        "import ember\n",
        "ember_dataframe = ember.read_metadata('/content/ember_2017_2/')\n",
        "ember_dataframe.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha256</th>\n",
              "      <th>appeared</th>\n",
              "      <th>label</th>\n",
              "      <th>subset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d4206650743b3d519106dea10a38a55c30467c3d9f7875...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
              "      <td>2007-01</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sha256 appeared  label subset\n",
              "0  0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12      0  train\n",
              "1  d4206650743b3d519106dea10a38a55c30467c3d9f7875...  2006-12      0  train\n",
              "2  c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01      0  train\n",
              "3  7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02      0  train\n",
              "4  ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02      0  train"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm0428Ih6PiN",
        "outputId": "c215406d-2753-4d51-8352-f607f01ef6cc"
      },
      "source": [
        "X_train, y_train, X_test, y_test = ember.read_vectorized_features('/content/ember_2017_2/')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.11.5-37bc2c9 found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpP2V6qPtIg6"
      },
      "source": [
        "# removing unlablled data from x_train and y_train dataset\n",
        "a = (y_train != -1)\n",
        "\n",
        "X_train = X_train[a]\n",
        "y_train = y_train[a]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpWUVdRGzxah"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "std_scale = RobustScaler()\n",
        "Xtrain_noramlized = std_scale.fit_transform(X_train)\n",
        "Xtest_noramlized = std_scale.fit_transform(X_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11dBxrluti53",
        "outputId": "8825d7a6-5081-4c9f-8e4c-43b2e726cbff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22gBahl4nm79"
      },
      "source": [
        "## **Loading data to HDF5 file and saving to drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W2hdrky6XOU"
      },
      "source": [
        "#Loading scaled X_train data to HDF5 file\n",
        "h54 = h5py.File('Xtrain_noramlized.h5', 'w')\n",
        "h54.create_dataset('Xtrain_noramlized', data=Xtrain_noramlized)\n",
        "h54.close()\n",
        "\n",
        "#Storing the h5 files to GDrive\n",
        "!cp Xtrain_noramlized.h5 /content/drive/MyDrive/ai-mid-term-data/ember_2017_2/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf3BzVTw2ig5"
      },
      "source": [
        "#Loading scaled X_test data to HDF5 file\n",
        "h55 = h5py.File('Xtest_noramlized.h5', 'w')\n",
        "h55.create_dataset('Xtest_noramlized', data=Xtest_noramlized)\n",
        "h55.close()\n",
        "\n",
        "#Storing the h5 files to GDrive\n",
        "!cp Xtest_noramlized.h5 /content/drive/MyDrive/ai-mid-term-data/ember_2017_2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc9CH8PJtdy0"
      },
      "source": [
        "# Loading y_train data to HDF5 file\n",
        "h51 = h5py.File('y_train.h5', 'w')\n",
        "h51.create_dataset('y_train', data=y_train)\n",
        "h51.close()\n",
        "\n",
        "!cp y_train.h5 /content/drive/MyDrive/ai-mid-term-data/ember_2017_2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5JA5yUxtg3Y"
      },
      "source": [
        "#Loading y_test data to HDF5 file\n",
        "h53 = h5py.File('y_test.h5', 'w')\n",
        "h53.create_dataset('y_test', data=y_test)\n",
        "h53.close()\n",
        "\n",
        "!cp y_test.h5 /content/drive/MyDrive/ai-mid-term-data/ember_2017_2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st409wqFnhH0"
      },
      "source": [
        "# **Reading h5 file from google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKbd5Ca9_ktg",
        "outputId": "dd8e8e47-f6fb-4dea-a828-b971d7e4a078"
      },
      "source": [
        "import h5py\n",
        "Xh5 = h5py.File('/content/drive/MyDrive/ai-mid-term-data/ember_2017_2/Xtrain_noramlized.h5','r')\n",
        "# Xh5 = h5py.File('Xtrain_noramlized.h5','r')\n",
        "X_train_normalized = Xh5['Xtrain_noramlized']\n",
        "X_train_normalized.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600000, 2381)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pyjaE7CAV70",
        "outputId": "0ba4be1b-1e4e-4e31-e968-5d0c40889447"
      },
      "source": [
        "import h5py\n",
        "Xh5 = h5py.File('/content/drive/MyDrive/ai-mid-term-data/ember_2017_2/Xtest_noramlized.h5','r')\n",
        "X_test_normalized = Xh5['Xtest_noramlized']\n",
        "X_test_normalized.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 2381)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8rGueHTy9vP",
        "outputId": "bfdfa58f-72a9-45b6-87c1-a5c2a6ecc748"
      },
      "source": [
        "# Reading y_train data from h5 files\n",
        "import h5py\n",
        "yh5 = h5py.File('/content/drive/MyDrive/ai-mid-term-data/ember_2017_2/y_train.h5','r')\n",
        "y_train = yh5['y_train']\n",
        "y_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600000,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmWLIP-4n6gB"
      },
      "source": [
        "# Reading y_test data from h5 files\n",
        "import h5py\n",
        "yth5 = h5py.File('/content/drive/MyDrive/ai-mid-term-data/ember_2017_2/y_test.h5','r')\n",
        "y_test = yth5['y_test']\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j7hcZUwAmFF"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQq5VGnsAjXO"
      },
      "source": [
        "def Model():\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(2381,))) \n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(units = 1000, activation ='relu' ))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(units = 1, activation='sigmoid'))\n",
        "    \n",
        "    \n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB01QM-6EXr7",
        "outputId": "77517a75-b402-45e9-bb11-ec16763daaea"
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout (Dropout)            (None, 2381)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              2382000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1001      \n",
            "=================================================================\n",
            "Total params: 2,383,001\n",
            "Trainable params: 2,383,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY_TqNIQFTgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd268556-192b-4ae5-db19-950591e43761"
      },
      "source": [
        "#Training the model on 1 epoch\n",
        "one_eph = model.fit(X_train_normalized, y_train,\n",
        "                batch_size=256, shuffle=\"batch\",\n",
        "                epochs=1, \n",
        "                validation_split=0.2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 480000 samples, validate on 120000 samples\n",
            "480000/480000 [==============================] - ETA: 0s - loss: 16233.5771 - accuracy: 0.8063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r480000/480000 [==============================] - 172s 359us/sample - loss: 16233.5771 - accuracy: 0.8063 - val_loss: 12010.2691 - val_accuracy: 0.7471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfzLII34M929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a284025-5f88-4693-818e-73bf2667cad8"
      },
      "source": [
        "#Training the model on 30 epoch\n",
        "training = model.fit(X_train_normalized, y_train,\n",
        "                batch_size=256, shuffle=\"batch\",\n",
        "                epochs=30, \n",
        "                validation_split=0.2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 480000 samples, validate on 120000 samples\n",
            "Epoch 1/30\n",
            "480000/480000 [==============================] - 158s 330us/sample - loss: 13926.9833 - accuracy: 0.8217 - val_loss: 16684.7998 - val_accuracy: 0.9095\n",
            "Epoch 2/30\n",
            "480000/480000 [==============================] - 174s 362us/sample - loss: 13020.0282 - accuracy: 0.8364 - val_loss: 15201.3106 - val_accuracy: 0.9115\n",
            "Epoch 3/30\n",
            "480000/480000 [==============================] - 160s 333us/sample - loss: 8058.4749 - accuracy: 0.8462 - val_loss: 14611.7020 - val_accuracy: 0.9126\n",
            "Epoch 4/30\n",
            "480000/480000 [==============================] - 163s 340us/sample - loss: 14988.7565 - accuracy: 0.8414 - val_loss: 14231.1877 - val_accuracy: 0.9148\n",
            "Epoch 5/30\n",
            "480000/480000 [==============================] - 175s 365us/sample - loss: 11278.2421 - accuracy: 0.8450 - val_loss: 21744.3439 - val_accuracy: 0.9127\n",
            "Epoch 6/30\n",
            "480000/480000 [==============================] - 170s 354us/sample - loss: 16588.0781 - accuracy: 0.8514 - val_loss: 22080.8863 - val_accuracy: 0.9047\n",
            "Epoch 7/30\n",
            "480000/480000 [==============================] - 156s 324us/sample - loss: 13053.7390 - accuracy: 0.8416 - val_loss: 20689.8126 - val_accuracy: 0.9106\n",
            "Epoch 8/30\n",
            "480000/480000 [==============================] - 177s 369us/sample - loss: 22098.7605 - accuracy: 0.8355 - val_loss: 20172.3839 - val_accuracy: 0.8941\n",
            "Epoch 9/30\n",
            "480000/480000 [==============================] - 174s 363us/sample - loss: 21463.3777 - accuracy: 0.8344 - val_loss: 19689.7311 - val_accuracy: 0.9150\n",
            "Epoch 10/30\n",
            "480000/480000 [==============================] - 154s 322us/sample - loss: 13699.8953 - accuracy: 0.8334 - val_loss: 20868.3348 - val_accuracy: 0.9153\n",
            "Epoch 11/30\n",
            "480000/480000 [==============================] - 169s 351us/sample - loss: 8705.6141 - accuracy: 0.8405 - val_loss: 20900.5573 - val_accuracy: 0.8992\n",
            "Epoch 12/30\n",
            "480000/480000 [==============================] - 175s 364us/sample - loss: 21975.2440 - accuracy: 0.8315 - val_loss: 18684.0660 - val_accuracy: 0.8861\n",
            "Epoch 13/30\n",
            "480000/480000 [==============================] - 154s 321us/sample - loss: 25290.2276 - accuracy: 0.8297 - val_loss: 16981.1126 - val_accuracy: 0.8983\n",
            "Epoch 14/30\n",
            "480000/480000 [==============================] - 166s 345us/sample - loss: 24112.4796 - accuracy: 0.8391 - val_loss: 25468.9044 - val_accuracy: 0.8688\n",
            "Epoch 15/30\n",
            "480000/480000 [==============================] - 176s 366us/sample - loss: 11118.1744 - accuracy: 0.8478 - val_loss: 11589.0964 - val_accuracy: 0.8731\n",
            "Epoch 16/30\n",
            "480000/480000 [==============================] - 166s 346us/sample - loss: 21108.6901 - accuracy: 0.8486 - val_loss: 16852.5008 - val_accuracy: 0.8844\n",
            "Epoch 17/30\n",
            "480000/480000 [==============================] - 157s 328us/sample - loss: 14493.1962 - accuracy: 0.8466 - val_loss: 21043.4679 - val_accuracy: 0.8748\n",
            "Epoch 18/30\n",
            "480000/480000 [==============================] - 177s 369us/sample - loss: 20110.6273 - accuracy: 0.8492 - val_loss: 25851.3941 - val_accuracy: 0.8968\n",
            "Epoch 19/30\n",
            "480000/480000 [==============================] - 171s 357us/sample - loss: 26170.0288 - accuracy: 0.8463 - val_loss: 35035.9417 - val_accuracy: 0.8817\n",
            "Epoch 20/30\n",
            "480000/480000 [==============================] - 154s 320us/sample - loss: 30297.6732 - accuracy: 0.8441 - val_loss: 28961.7492 - val_accuracy: 0.8746\n",
            "Epoch 21/30\n",
            "480000/480000 [==============================] - 174s 362us/sample - loss: 15251.3431 - accuracy: 0.8471 - val_loss: 21511.8044 - val_accuracy: 0.8692\n",
            "Epoch 22/30\n",
            "480000/480000 [==============================] - 175s 364us/sample - loss: 23126.1434 - accuracy: 0.8447 - val_loss: 20268.4924 - val_accuracy: 0.8733\n",
            "Epoch 23/30\n",
            "480000/480000 [==============================] - 153s 319us/sample - loss: 43057.8040 - accuracy: 0.8418 - val_loss: 18006.4524 - val_accuracy: 0.8711\n",
            "Epoch 24/30\n",
            "480000/480000 [==============================] - 168s 350us/sample - loss: 9393.2007 - accuracy: 0.8457 - val_loss: 16867.8722 - val_accuracy: 0.8752\n",
            "Epoch 25/30\n",
            "480000/480000 [==============================] - 173s 360us/sample - loss: 28539.0910 - accuracy: 0.8432 - val_loss: 19678.5521 - val_accuracy: 0.8643\n",
            "Epoch 26/30\n",
            "480000/480000 [==============================] - 159s 331us/sample - loss: 37166.9924 - accuracy: 0.8369 - val_loss: 25602.9133 - val_accuracy: 0.8596\n",
            "Epoch 27/30\n",
            "480000/480000 [==============================] - 162s 337us/sample - loss: 29401.5936 - accuracy: 0.8427 - val_loss: 21315.8270 - val_accuracy: 0.8750\n",
            "Epoch 28/30\n",
            "480000/480000 [==============================] - 175s 365us/sample - loss: 15738.6220 - accuracy: 0.8400 - val_loss: 24249.1921 - val_accuracy: 0.8775\n",
            "Epoch 29/30\n",
            "480000/480000 [==============================] - 165s 344us/sample - loss: 23193.6270 - accuracy: 0.8373 - val_loss: 28145.9157 - val_accuracy: 0.8619\n",
            "Epoch 30/30\n",
            "480000/480000 [==============================] - 159s 331us/sample - loss: 27707.3060 - accuracy: 0.8337 - val_loss: 28651.3787 - val_accuracy: 0.8597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsQfzRjPMS0Z",
        "outputId": "32565d78-0143-49ae-e354-0b4260e487dd"
      },
      "source": [
        "# testing the model\n",
        "\n",
        "score =model.evaluate(X_test_normalized,y_test)\n",
        "print(\"Training accuracy:\", score[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.797225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jhAK-7vOLQQ"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/ai-mid-term-data/ember_2017_2/\"+'model.h5')\n",
        "\n",
        "# save neural network structure to JSON \n",
        "model_json = model.to_json()\n",
        "with open(\"mid_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights('model_weights.h5')\n",
        "\n",
        "#Storing the weight to GDrive\n",
        "!cp ./mid_model.json /content/drive/MyDrive/ai-mid-term-data/ember_2017_2/\n",
        "\n",
        "!cp ./model_weights.h5 /content/drive/MyDrive/ai-mid-term-data/ember_2017_2/\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8-x2iGmdTW"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vqn_hTDFbj7",
        "outputId": "f01ac532-edb0-4ccc-dcb6-9728e0f3c8db"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "test_model = keras.models.load_model(\"/content/drive/MyDrive/ai-mid-term-data/ember_2017_2/\"+'model.h5')\n",
        "\n",
        "test_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results =test_model.evaluate(X_test_normalized,y_test)\n",
        "print(\"loss: %gl,acc: %gl\"%(results[0],results[1]))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 13741.9l,acc: 0.797225l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9CPYaikuR7M"
      },
      "source": [
        "def perd_pefile(pefile):\n",
        "  import os\n",
        "  import json\n",
        "  try:\n",
        "    import ember\n",
        "  except:\n",
        "    os.system('wget https://github.com/endgameinc/ember/archive/master.zip')\n",
        "    os.system('unzip master.zip')\n",
        "    os.system('rm master.zip')\n",
        "    os.system('cp -r ember-master/* .')\n",
        "    os.system('rm -r ember-master')\n",
        "    os.system('pip install -r requirements.txt')\n",
        "    os.system('python setup.py install')\n",
        "    import ember\n",
        "\n",
        "    from sklearn.preprocessing import RobustScaler\n",
        "    rs = RobustScaler()\n",
        "       \n",
        "  print(\"test1\")\n",
        "  test_pe = open(pefile, \"rb\").read()\n",
        "  extract = ember.PEFeatureExtractor() \n",
        "  data = extract.feature_vector(test_pe) \n",
        "  scaled_data = rs.fit_transform([data])\n",
        "  X_data = np.reshape(scaled_data,(1, 2381))\n",
        "\n",
        "  model = tf.keras.models.load_model('/content/drive/MyDrive/ai-mid-term-data/ember_2017_2/model.h5')\n",
        "  pred = model.predict_classes(X_data)\n",
        "\n",
        "  return pred"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz6oDZL3v0A8"
      },
      "source": [
        "perd_pefile(\"putty.exe\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}